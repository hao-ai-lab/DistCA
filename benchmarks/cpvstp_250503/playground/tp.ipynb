{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import flashinfer\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(q_length, kv_length, rank, batch_size):\n",
    "    a = torch.zeros((q_length, kv_length), dtype=torch.bool)\n",
    "    b = torch.ones((q_length, kv_length), dtype=torch.bool)\n",
    "\n",
    "    # Upper\n",
    "    for i in range(q_length):\n",
    "        right = rank * q_length + i + 1\n",
    "        a[i, :right] = True\n",
    "    for i in range(q_length):\n",
    "        start = kv_length - q_length * (rank+1) + i + 1\n",
    "        # print(start)\n",
    "        b[i, start:] = False\n",
    "        pass\n",
    "    # concat a, b \n",
    "    c = torch.cat([a, b], dim=0)\n",
    "    # replicate c `batch_size` times\n",
    "    d = torch.cat([c] * batch_size, dim=0)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flash_attention(rank=0, batch_size=1, qo_len=128, kv_len=4096, num_qo_heads=32, num_kv_heads=32, head_dim=128, repeat=7, visualize_mask=False,device=\"cuda\",return_tensors=False,verbose=False):\n",
    "    def print_if_verbose(s):\n",
    "        if verbose:\n",
    "            print(s)\n",
    "        return\n",
    "    \n",
    "    print_if_verbose(f\"Running flash attention with rank {rank}, batch size {batch_size}, qo_len {qo_len}, kv_len {kv_len}, num_qo_heads {num_qo_heads}, num_kv_heads {num_kv_heads}, head_dim {head_dim}, visualize_mask {visualize_mask}, device {device}, verbose {verbose}\")\n",
    "    q = torch.randn(qo_len * batch_size, num_qo_heads, head_dim).half().to(device)\n",
    "    k = torch.randn(kv_len, num_kv_heads, head_dim).half().to(device)\n",
    "    v = torch.randn(kv_len, num_kv_heads, head_dim).half().to(device)\n",
    "    \n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    compute_times = []\n",
    "    for _ in range(repeat):\n",
    "        start_event.record()\n",
    "        o_custom = flashinfer.single_prefill_with_kv_cache(q, k, v, custom_mask=mask)\n",
    "        end_event.record()\n",
    "\n",
    "        # Waits for everything to finish running\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "        compute_times.append(elapsed_time_ms)\n",
    "        print_if_verbose(f\"Elapsed time: {elapsed_time_ms:.2f} ms\")\n",
    "    \n",
    "    return_values = [None, compute_times]\n",
    "    if return_tensors:\n",
    "        return_values[0] = o_custom\n",
    "    return return_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
