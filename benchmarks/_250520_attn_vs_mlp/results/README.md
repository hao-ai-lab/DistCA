# Results: Ours vs WLB-LLM


## batch (33K total) = [32] + [1]

Ours:
([(array([1024]), 1, 1), (array([32768]), 4, 2)], 6.84)

WLB LLM[TP=1, CP=1, DP=16]:
([array([32768]), array([1024])], 77.2405)

WLB LLM[TP=8, CP=1, DP=2]:
([array([32768]), array([1024])], 11.938)

WLB LLM[TP=8, CP=2, DP=1]:
([array([32768,  1024])], 9.76175)

WLB LLM[TP=2, CP=8, DP=1]:
([array([32768,  1024])], 23.06675)



## batch (64K total) = [32] + [1] * 32


Ours: 
[ (array([32768]), 4, 2), (array([1024, 1024, 1024, 1024]), 1, 1), (array([1024, 1024, 1024, 1024]), 1, 1), (array([1024, 1024, 1024, 1024]), 1, 1), (array([1024, 1024, 1024, 1024]), 1, 1), (array([1024, 1024, 1024, 1024]), 1, 1), (array([1024, 1024, 1024, 1024]), 1, 1), (array([1024, 1024, 1024, 1024]), 1, 1),]
max latency : 6.84 ms + 11.107 ms = 17.947 ms


WLB LLM[TP=2, CP=8, DP=1]:
([array([32768,  1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,
          1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,
          1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,
          1024,  1024,  1024,  1024,  1024,  1024])],
 87.62425)


WLB LLM[TP=8, CP=1, DP=2]:
 ([array([1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
         1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]),
  array([32768,  1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,
          1024,  1024,  1024])],
 23.91425)


WLB LLM[TP=8, CP=2, DP=1]:
([array([32768,  1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,
          1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,
          1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,  1024,
          1024,  1024,  1024,  1024,  1024,  1024])],
 44.877)

WLB LLM[TP=4, CP=1, DP=4]:
([array([32768]),
  array([1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]),
  array([1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]),
  array([1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024])],
 20.69325)



## batch (64K total) = [64] + [2] * 32

Ours: (36 GPU)
[ (array([65536]), 8, 4), (array([2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048]), 1, 1), (array([2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048]), 1, 1), (array([2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048]), 1, 1), (array([2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048]), 1, 1)]
max latency : 7.93ms + 10.88ms = 18.81ms


WLB LLM[TP=8, CP=2, DP=2]: (36 GPU, actually used 32 GPU)
([array([65536,  2048,  2048,  2048,  2048,  2048,  2048,  2048,  2048,
          2048]),
  array([2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048,
         2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048,
         2048])],
 26.26525)